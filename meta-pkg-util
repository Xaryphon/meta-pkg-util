#!/usr/bin/env python

import os
from os import path
from datetime import datetime
import gzip
from hashlib import sha256, md5
import tarfile
import io
import tempfile
import re
import string
import base64
import argparse
import commentjson as json
import zstandard as zstd
import gnupg

TOOL_NAME = "meta-pkg-util"
TOOL_VERSION = "0.2.2"

added_files = []

def tarinfo(name, size, mtime: datetime, ftype = tarfile.REGTYPE, mode = 0o644):
    info = tarfile.TarInfo(name = name)
    info.size = size
    info.mtime = float(mtime.strftime("%s.%f"))
    info.mode = mode
    info.type = ftype
    info.uid = info.gid = 0
    info.uname = info.gname = 'root'
    return info

def pkginfo_to_text(pkginfo):
    class PkgInfoIter:
        def __init__(self, pkginfo):
            self.pkginfo = pkginfo

        def __iter__(self):
            self.iter = iter(self.pkginfo.items())
            self.tmp_key  = None
            self.tmp_iter = None
            return self

        def __next__(self):
            while True:
                if self.tmp_iter:
                    try:
                        return (self.tmp_key, next(self.tmp_iter))
                    except StopIteration:
                        self.tmp_key  = None
                        self.tmp_iter = None
                (k, v) = next(self.iter)
                if k.startswith("_"):
                    continue
                if isinstance(v, list):
                    if v:
                        self.tmp_key  = k
                        self.tmp_iter = iter(v)
                    continue
                return (k, v)

    return '\n'.join([f"{k} = {v}" for (k, v) in PkgInfoIter(pkginfo)])

def makepkg(now, repo, outdir, pkginfo_data, gpg, signkey):
    pkgver = now.strftime("%Y%m%dT%H%M%SZ-1")
    builddate = now.strftime("%s")

    pkginfo_data["pkgver"] = pkgver
    pkginfo_data["builddate"] = builddate

    pkgname = pkginfo_data["pkgname"]
    arch = pkginfo_data["arch"]

    pkginfo = (
        f"# Generated by {TOOL_NAME} {TOOL_VERSION}\n" +
        pkginfo_to_text(pkginfo_data)
    ).encode()

    mtree = '\n'.join([
        "#mtree",
        "/set type=file uid=0 gid=0 mode=644",
        "./.PKGINFO time={} size={} md5digest={} sha256digest={}".format(now.strftime("%s.0"), len(pkginfo), md5(pkginfo).hexdigest(), sha256(pkginfo).hexdigest())
    ]).encode()

    outfilename = f"{pkgname}-{pkgver}-{arch}.pkg.tar.zst"
    with io.BytesIO() as outfile:
        with zstd.open(outfile, "wb") as zst_file:
            with tarfile.open(fileobj=zst_file, mode="w") as tar:
                with io.BytesIO(pkginfo) as file:
                    tar.addfile(tarinfo(".PKGINFO", len(pkginfo), now), fileobj=file)
                with io.BytesIO(mtree) as file:
                    tar.addfile(tarinfo(".MTREE", len(mtree), now), fileobj=file)
        outdata = outfile.getvalue()

    added_files.append(path.join(outdir, outfilename))
    with open(path.join(outdir, outfilename), 'wb') as outfile:
        outfile.write(outdata)

    if signkey:
        # pylint: disable=no-member
        sigres = gpg().sign(outdata, detach=True, binary=True, keyid=signkey)
        sigdata = sigres.data

        if not sigdata:
            print(f"ERROR package {repo} {pkgname} Failed to sign package: {sigres.status}")
            raise RuntimeError("sign failed with " + sigres.status)

        added_files.append(path.join(outdir, outfilename + '.sig'))
        with open(path.join(outdir, outfilename + '.sig'), 'wb') as sigfile:
            sigfile.write(sigdata)

        sigb64 = base64.b64encode(sigdata).decode()
    else:
        sigb64 = ''

    return {
        "FILENAME": outfilename,
        "NAME": pkgname,
        "BASE": pkginfo_data["pkgbase"],
        "VERSION": pkgver,
        "DESC": pkginfo_data["pkgdesc"] or '',
        "GROUPS": '\n'.join(pkginfo_data["group"]),
        "CSIZE": len(outdata),
        "ISIZE": pkginfo_data["size"],
        "MD5SUM": md5(pkginfo).hexdigest(),
        "SHA256SUM": sha256(pkginfo).hexdigest(),
        "PGPSIG": sigb64,
        "URL": pkginfo_data["url"] or '',
        #"LICENSE": '', # TODO: Maybe implement licenses
        "ARCH": arch,
        "BUILDDATE": pkginfo_data["builddate"],
        "PACKAGER": pkginfo_data["packager"] or '',
        "REPLACES": '\n'.join(pkginfo_data["replaces"]),
        "CONFLICTS": '\n'.join(pkginfo_data["conflict"]),
        "PROVIDES": '\n'.join(pkginfo_data["provides"]),
        "DEPENDS": '\n'.join(pkginfo_data["depend"]),
        "OPTDEPENDS": '\n'.join(pkginfo_data["optdepend"]),
        #"MAKEDEPENDS": '\n'.join(pkginfo_data["makedepend"]),
        #"CHECKDEPENDS": '\n'.join(pkginfo_data["checkdepend"])
    }

def compare_pkginfo_desc(pkginfo, desc):
    def compare_value(a, b):
        if (a is None or not str(a)) and (b is None or not str(b)):
            return True
        if isinstance(a, list):
            if not isinstance(b, list):
                if b is not None:
                    b = [b]
                else:
                    b = []
        elif not isinstance(a, str) and a is not None:
            a = str(a)
        return a == b

    def compare_dict(a, b, keymap):
        for (ak, bk) in keymap:
            av = a.get(ak)
            bv = b.get(bk)
            if not compare_value(av, bv):
                #print(f"comparing ({type(av)}){av} to ({type(bv)}){bv}")
                return False
        return True
    return compare_dict(pkginfo, desc, [
        # pkginfo        desc
        ("pkgname",     "NAME"),
        ("pkgbase",     "BASE"),
        ("pkgdesc",     "DESC"),
        ("group",       "GROUPS"),
        ("size",        "ISIZE"),
        ("url",         "URL"),
        ("license",     "LICENSE"),
        ("arch",        "ARCH"),
        ("packager",    "PACKAGER"),
        ("replaces",    "REPLACES"),
        ("conflict",    "CONFLICTS"),
        ("provides",    "PROVIDES"),
        ("depend",      "DEPENDS"),
        ("optdepend",   "OPTDEPENDS"),
        ("makedepend",  "MAKEDEPENDS"),
        ("checkdepend", "CHECKDEPENDS")
    ])

DESC_HEADER_REGEX = re.compile('^%(.*)%$')

def parse_pkg_desc(desc: str):
    data = {}
    key = ''
    for line in desc.splitlines():
        if not line:
            continue

        match = DESC_HEADER_REGEX.match(line)
        if match:
            key = match.group(1)
            continue

        if key in data:
            if not isinstance(data[key], list):
                data[key] = [data[key]]
            data[key].append(line)
        else:
            data[key] = line
    return data

def cleanup(repo, file):
    def _cleanup(file):
        try:
            if path.exists(file):
                print(f"INFO cleanup {repo} {file}")
                os.remove(file)
        except:
            print(f"WARNING cleanup {repo} {file} Failed")

    _cleanup(file)

def backup(file):
    if path.exists(file + '.old'):
        os.remove(file + '.old')
    os.rename(file, file + '.old')

def restore(file):
    if path.exists(file):
        os.remove(file)
    os.rename(file + '.old', file)

def build_repo(now, name, infile, outdir, pkg_defaults, lvars, gpg, signkey):
    global added_files

    _cleanup_restore_db = False
    _cleanup_restore_sig = False
    def on_error(e):
        if _cleanup_restore_db:
            try:
                restore(dbpath)
            except:
                print(f"FATAL repo-db {name} Restoring db failed")

        if _cleanup_restore_sig:
            try:
                restore(dbpath + '.sig')
            except:
                print(f"FATAL repo-db {name} Restoring db sig failed")

        for f in added_files:
            cleanup(name, f)

        raise RuntimeError from e

    os.makedirs(outdir, exist_ok=True)
    arch = 'any'
    isize = 0 # Install size (not sure if this should be 0 or something a little more just to be safe)

    dbext  = '.db.tar.zst'
    dbbase = path.join(outdir, name)
    dbpath = dbbase + dbext

    with open(infile, 'r') as json_file:
        json_data = json.load(json_file)

    default = json_data.get('_default_', {})

    # x -> _default_ -> lvars -> y
    def get_value(dic, name, default_value = []):
        v = dic.get(name, default.get(name, pkg_defaults.get(name, default_value)))
        if isinstance(v, list):
            return [string.Template(x).substitute(lvars) for x in v]
        return string.Template(v).substitute(lvars)

    desired_pkginfos = {}
    for (pkgname, data) in json_data.items():
        if pkgname == '_default_':
            continue

        pkgname = string.Template(pkgname).substitute(lvars)

        if pkgname in desired_pkginfos:
            print(f"ERROR repo-gather {name} Package {pkgname} defined twice.")
            raise RuntimeError(pkgname + " defined twice")

        pkginfo = {
            "pkgname": pkgname,
            "pkgbase": pkgname, # maybe support custom pkgbase
            # pkgver gets added later but probably could be moved here
            "pkgdesc": get_value(data, 'description'),
            "url": get_value(data, 'url'),
            # builddate gets added later but probably could be moved here
            "packager": get_value(data, 'packager'),
            "size": isize,
            "arch": arch,
            #"license": get_value(data, 'license'),
            "replaces": get_value(data, 'replaces'),
            "group": get_value(data, 'groups'),
            "conflict": get_value(data, 'conflicts'),
            "provides": get_value(data, 'provides'),
            #"backup": get_value(data, 'backup'),
            "depend": get_value(data, 'depends'),
            "optdepend": get_value(data, 'optdepends'),
            #"makedepend": get_value(data, 'makedepends'),
            #"checkdepend": get_value(data, 'checkdepends'),
            "_signkey": get_value(data, 'signkey')
        }

        desired_pkginfos[pkgname] = pkginfo

    always_new = not path.exists(dbpath)

    descs = {}
    add_pkginfos = []
    toremove = []

    if not always_new:
        # zstd stream doesn't support seeking and tarfile wants to seek so we have to use a temp file
        try:
            with tempfile.TemporaryFile('w+b') as tmp_file:
                with zstd.open(dbpath, "rb") as zst_file:
                    tmp_file.write(zst_file.read())
                tmp_file.seek(0)
                with tarfile.open(fileobj=tmp_file, mode='r') as tar:
                    for info in tar:
                        if not info.isreg():
                            continue
                        desc = tar.extractfile(info).read().decode()
                        pdesc = parse_pkg_desc(desc)
                        pkgname = pdesc['NAME']
                        if pkgname in desired_pkginfos:
                            pkginfo = desired_pkginfos[pkgname]
                            uptodate = compare_pkginfo_desc(pkginfo, pdesc)

                            if uptodate:
                                fdesc = {}
                                for (dk, dv) in pdesc.items():
                                    if isinstance(dv, list):
                                        fdesc[dk] = '\n'.join(dv)
                                    else:
                                        fdesc[dk] = dv
                                if pkgname in descs:
                                    raise RuntimeError("We shouldn't be here")
                                descs[pkgname] = fdesc
                            else:
                                toremove.append(pdesc['FILENAME'])
                                print(f"INFO repo-misc {name} updating {pkgname}")
                                pkginfo['_is_updating'] = True
                        else:
                            toremove.append(pdesc['FILENAME'])
        except Exception as e:
            print(f"ERROR repo-gather {name} unexpected error occured")
            raise RuntimeError from e

        for (pkgname, pkginfo) in desired_pkginfos.items():
            if not pkgname in descs:
                add_pkginfos.append(pkginfo)
    else:
        add_pkginfos = desired_pkginfos.values()

    # unsafe starts here

    for pkginfo in add_pkginfos:
        try:
            pkgname = pkginfo['pkgname']
            if not pkginfo.get('_is_updating', False):
                print(f"INFO repo-misc {name} adding {pkgname}")
            if pkgname in descs:
                raise RuntimeError("We shouldn't be here")
            desc = makepkg(now, name, outdir, pkginfo, gpg, pkginfo.get('_signkey'))
            descs[pkgname] = desc
        except Exception as e:
            print(f"ERROR package {name} {pkgname} Failed to create package")
            on_error(e)

    if not len(toremove) and not len(add_pkginfos):
        print(f"INFO repo-db {name} update unnecessary")
        return

    # Backup db
    try:
        if path.exists(dbpath):
            backup(dbpath)
            _cleanup_restore_db = True
    except Exception as e:
        print(f"ERROR repo-db {name} Backing up db failed")
        on_error(e)

    if signkey:
        try:
            if path.exists(dbpath + '.sig'):
                backup(dbpath + '.sig')
                _cleanup_restore_sig = True
        except Exception as e:
            print(f"ERROR repo-db {name} Backing up db sig failed")
            on_error(e)

    try:
        with zstd.open(dbpath, "wb") as zst_file:
            with tarfile.open(fileobj=zst_file, mode='w') as tar:
                for desc in descs.values():
                    pkg_dir = f"{desc['NAME']}-{desc['VERSION']}"
                    pkg_desc = path.join(pkg_dir, 'desc')

                    pkg_desc_data = ''.join([
                        # Write everything that's not an empty string
                        f"%{k}%\n{v}\n\n" for (k, v) in desc.items() if not isinstance(v, (str, type(None))) or v
                    ]).encode()

                    tar.addfile(tarinfo(pkg_dir, 0, now, ftype=tarfile.DIRTYPE, mode=0o755))
                    with io.BytesIO(pkg_desc_data) as file:
                        tar.addfile(tarinfo(pkg_desc, len(pkg_desc_data), now), fileobj=file)
    except Exception as e:
        print(f"ERROR repo-db {name} Creating of db failed")
        on_error(e)

    if signkey:
        print(f"INFO repo-db {name} Signing")
        try:
            with open(dbpath, 'rb') as zst_file:
                sigres = gpg().sign_file(zst_file, detach=True, binary=True, keyid=signkey)

            # pylint: disable=no-member
            sigdata = sigres.data

            if not sigdata:
                print(f"ERROR repo-db {name} {pkgname} Failed to sign db: {sigres.status}")
                raise RuntimeError("sign failed with " + sigres.status)

            with open(dbpath + '.sig', 'wb') as sigfile:
                sigfile.write(sigdata)
        except Exception as e:
            print(f"ERROR repo-db {name} Signing of db failed")
            on_error(e)

    # <repo>.db -> <repo>.db.tar.zst
    # <repo>.files -> <repo>.db.tar.zst
    if not path.exists(dbbase + '.db'):
        os.symlink(name + dbext, dbbase + '.db')
    if not path.exists(dbbase + '.files'):
        os.symlink(name + dbext, dbbase + '.files')

    if signkey:
        if not path.exists(dbbase + '.db.sig'):
            os.symlink(name + dbext + '.sig', dbbase + '.db.sig')
        if not path.exists(dbbase + '.files.sig'):
            os.symlink(name + dbext + '.sig', dbbase + '.files.sig')

    added_files = []

    for f in toremove:
        cleanup(name, path.join(outdir, f))
        cleanup(name, path.join(outdir, f + '.sig'))

def dict_combine(lower, upper):
    r = dict(upper)
    for (k, v) in lower.items():
        if not k in r:
            r[k] = v
    return r

def build_repos(now, config: dict, gpg, cfgdir):
    user_vars = config.get('variables', {})
    repo_defaults = config.get('repository_defaults', {})
    pkg_defaults = config.get('package_defaults', {})

    user_vars['cfgdir'] = cfgdir

    for (k, v) in user_vars.items():
        user_vars[k] = string.Template(v).substitute(user_vars)

    for repo in config['repositories']:
        repo_name = repo['name']
        repo_pkg_defaults = dict_combine(pkg_defaults, repo.get('package_defaults', {}))
        repo_infile = repo.get('infile', repo_defaults.get('infile', None))
        repo_outdir = repo.get('outdir', repo_defaults.get('outdir', None))
        repo_signkey = repo.get('signkey', repo_defaults.get('signkey', ''))

        if not (repo_name and repo_infile and repo_outdir):
            raise RuntimeError('name, infile and outfile must be set for a repository')

        lvars = dict_combine(user_vars, {'name': repo_name})
        repo_infile = string.Template(repo_infile).substitute(lvars)
        repo_outdir = string.Template(repo_outdir).substitute(lvars)
        repo_signkey = string.Template(repo_signkey).substitute(lvars)

        build_repo(now, repo_name, repo_infile, repo_outdir, repo_pkg_defaults, lvars, gpg, repo_signkey)

def main():
    def gpg():
        if not gpg._: gpg._ = gnupg.GPG(use_agent=True)
        return gpg._
    gpg._ = None
    now = datetime.utcnow()

    parser = argparse.ArgumentParser()
    parser.add_argument("-c", "--config", type=str, required=True, help="Path to config file")
    args = parser.parse_args()

    with open(args.config, 'r') as json_file:
        config = json.load(json_file)

    build_repos(now, config, gpg, path.dirname(path.abspath(args.config)))

if __name__ == "__main__":
    main()
